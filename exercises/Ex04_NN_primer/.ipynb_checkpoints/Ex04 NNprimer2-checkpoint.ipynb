{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise #4: neural networks primer (part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time we covered\n",
    "\n",
    "**Phase 1 : set it up**\n",
    "\n",
    " 1. use case\n",
    " 2. from logit to neural network\n",
    " 3. nn structure: weights and biases\n",
    " 3. activation function\n",
    " 4. softmax\n",
    " 5. application\n",
    " \n",
    "To proceed we will need to run some code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00635426]\n",
      " [0.01998603]\n",
      " [0.01393413]\n",
      " [0.00850893]\n",
      " [0.87939691]\n",
      " [0.07181974]]\n",
      "[0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#Load dataset\n",
    "app = pd.read_csv(\"data/PrepApp.csv\",index_col=False,sep='\\t', encoding='utf-8')\n",
    "app=app.set_index('track_name')\n",
    "\n",
    "#Define functions\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def ReLU(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "#Prepae your data, starting with dummies for target var\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(app[\"user_rating\"])\n",
    "encoded_Y = encoder.transform(app[\"user_rating\"])\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "data = np.array(app)\n",
    "\n",
    "X = data[:,:-1]\n",
    "y = dummy_y.astype(int)\n",
    "\n",
    "# We will feed in the 6th observation\n",
    "inputs = np.array(X[5]).reshape( (35,1) )\n",
    "targets = np.array(y[5]).reshape( (6,1) )\n",
    "\n",
    "#Set up the NN structure\n",
    "inputLayer = 35 \n",
    "hiddenLayer = 50 \n",
    "outputLayer = 6 \n",
    "\n",
    "#Set weights and biases\n",
    "np.random.seed(9)\n",
    "limit = np.sqrt(6 / (inputLayer + outputLayer))\n",
    "weightsInputToHidden = np.random.uniform(-limit, limit, (hiddenLayer, inputLayer))\n",
    "weightsHiddenToOutput = np.random.uniform(-limit, limit, (outputLayer, hiddenLayer))\n",
    "biasInputToHidden = np.ones( (hiddenLayer,1) ) \n",
    "biasHiddenToOutput = np.ones( (outputLayer,1) )\n",
    "\n",
    "#Start the forward pass\n",
    "hL_inputs = np.dot(weightsInputToHidden, inputs) + biasInputToHidden\n",
    "hL_outputs = ReLU(hL_inputs)\n",
    "oL_inputs = np.dot(weightsHiddenToOutput, hL_outputs) + biasHiddenToOutput\n",
    "oL_outputs = softmax(oL_inputs)\n",
    "\n",
    "#Check your results\n",
    "print(oL_outputs)\n",
    "print(y[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: make it work # \n",
    " - loss function\n",
    " - stochastic gradient descent\n",
    " - learning rate\n",
    " - momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "### Logistic regression case\n",
    "$$J(w) = \\sum_{i=1}^{m} y^{(i)} \\log P(y=1) + (1 - y^{(i)}) \\log P(y=0)$$\n",
    "Where P(y) represent the probability of a certain binary outcome\n",
    "\n",
    "We will however consider another loss functin - cross entropy. It is used when output represents the probability of an outcome, i.e. when the output is a probability distribution. It is used as a loss function in neural networks which have softmax activations in the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-entropy \n",
    "Entropy (H(y)) is a term from Information Theory. It had a great impact on the field of communication and signifies the optimal number of bits to encode a certain information content ($y_i$ is the probability of the i-th event, symbol or in our case class):\n",
    "\n",
    "$$H(y) = \\sum_i y_i \\log \\frac{1}{y_i} = -\\sum_i y_i \\log y_i$$\n",
    "\n",
    "Now the cross-entropy (H(y,y^)) is the number of bits we'll need if we encode symbols from  y using the wrong tool y^. Cross entropy is always bigger or equal to entropy. Mind that i stands for the number of classes. \n",
    "\n",
    "$$H(y, \\hat{y}) = \\sum_i y_i \\log \\frac{1}{\\hat{y}_i} = -\\sum_i y_i \\log \\hat{y}_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly enough, the The KL divergence that you have encountered before in BADS (uplift random forest) is simply the difference between cross entropy and entropy:\n",
    "$$\\mbox{KL}(y~||~\\hat{y})\n",
    "= \\sum_i y_i \\log \\frac{1}{\\hat{y}_i} - \\sum_i y_i \\log \\frac{1}{y_i}\n",
    "= \\sum_i y_i \\log \\frac{y_i}{\\hat{y}_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would be calculating the cross-entropy for every vector of true/estimated probabilities and averaging it over the sample or batch (more about it later) - this will be our loss function *L* that we will ultimately want to minimise (class i, smaple j):\n",
    "\n",
    "$$L=-\\frac{1}{N}\\sum_j \\sum_i y_i \\log(yhat)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-9b1662d53cce>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-9b1662d53cce>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    -1.0 * [ ln(0.20) * 0.15 + ln(0.40) * 0.35 + ln(0.30) * 0.25 + ln(0.10) * 0.25 ] =\u001b[0m\n\u001b[1;37m                                                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#CE example\n",
    "#A concrete example is the best way to explain the purely mathematical form of CE. Suppose you have a weirdly shaped four-sided dice (yes, I know the singular is really \"die\").\n",
    "#Using some sort of intuition or physics, you predict that the probabilities of the four sides are (0.20, 0.40, 0.30, 0.10). \n",
    "# Then you roll the dice many thousands of times and determine that the true probabilities are (0.15, 0.35, 0.25, 0.25). \n",
    "# The CE error for your prediction is:\n",
    "-1.0 * [ ln(0.20) * 0.15 + ln(0.40) * 0.35 + ln(0.30) * 0.25 + ln(0.10) * 0.25 ] =\n",
    "-1.0 * [ (-1.61)(0.15) + (-0.92)(0.35) + (-1.20)(0.25) + (-2.30)(0.25) ] =\n",
    "1.44\n",
    "#https://visualstudiomagazine.com/articles/2017/07/01/cross-entropy.aspx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"softmax.png\" alt=\"ffff\" style=\"width: 600px\">\n",
    "\n",
    "Source: https://www.ritchieng.com/machine-learning/deep-learning/neural-nets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = y[5]\n",
    "yhat=np.round(oL_outputs, 3) #that's our WX+b run through softmax\n",
    "print(yhat,yhat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=-sum(true*np.log(yhat))\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(true, true.shape)\n",
    "#print(yhat,yhat.shape)\n",
    "#Let's define loss function\n",
    "\n",
    "L=-sum(true*np.log(yhat))\n",
    "print(L) #doesnt look quite right...let's see what went wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true*np.log(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true*np.log(yhat.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=-sum(true*np.log(yhat.flatten()))\n",
    "print(L)\n",
    " # we are summing over classes, not over obs, as we have only one observation!\n",
    "#the loss function values seems right now, let's see how we can improve it    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the number we want the coomputer to minimize! But how?\n",
    "We can not change our input, we cannoo change our labels, what we can **update weights and biases** - these are the parameters of our neural network. So we need to change our **W, M, b and v** see if loss function decreases.\n",
    "NB: number of neurons in the hidden layer AND number of hidden layers are hyperparameters and certainly can be experimented with, we will discuss it further down the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most efficient way to move around the function slope is to find the derivative.\n",
    "\n",
    "In our naive example N=1, as we are only dealing with 1 batch (j=1), while we have 6 classes (i=6).\n",
    "\n",
    "But i an j would potentially go into thousands, calculating the derivative of the loss function will become extremely hard. \n",
    "\n",
    "And that was the point when everybody almost gave up on neural networks. Spoiler alert: the solutions were **stochastic gradient descent and backpropagation**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://giphy.com/embed/8tvzvXhB3wcmI\" width=\"1000\" height=\"400\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n",
       "<p><a href=\"https://giphy.com/gifs/deep-learning-8tvzvXhB3wcmI\">via GIPHY</a></p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://giphy.com/embed/8tvzvXhB3wcmI\" width=\"1000\" height=\"400\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n",
    "<p><a href=\"https://giphy.com/gifs/deep-learning-8tvzvXhB3wcmI\">via GIPHY</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will try to find the local minimum of (x-4)^2 function. In this case gradient is a simple derivative\n",
    "\n",
    "cur_x = 10 \n",
    "rate = 0.1 # Learning rate\n",
    "precision = 0.000001 #This tells us when to stop the algorithm\n",
    "previous_step_size = 1 #\n",
    "max_iters = 40 # maximum number of iterations\n",
    "iters = 0 #iteration counter\n",
    "df = lambda x: 2*(x-4) #Gradient of our function '\n",
    "\n",
    "while previous_step_size > precision and iters < max_iters:\n",
    "    prev_x = cur_x #Store current x value in prev_x\n",
    "    cur_x = cur_x - rate * df(prev_x) #Grad descent\n",
    "    previous_step_size = abs(cur_x - prev_x) #Change in x\n",
    "    iters = iters+1 #iteration count\n",
    "    print(\"Iteration\",iters,\"\\nX value is\",cur_x) #Print iterations\n",
    "    \n",
    "print(\"The local minimum occurs at\", cur_x)\n",
    "\n",
    "#https://towardsdatascience.com/implement-gradient-descent-in-python-9b93ed7108d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient\n",
    "The gradient ( $\\nabla$) is a vector operation which operates on a scalar function to produce a vector whose magnitude is the maximum rate of change of the function at the point of the gradient and which is pointed in the direction of that maximum rate of change. \n",
    "\n",
    "Well, put in easier terms, gradient is a **vector of partial derivatives**. Why would we need it? Because we need the derivative of this:\n",
    "$$L=-\\frac{1}{N}\\sum\\sum y\\log(softmax(M(relu(Wa+b))+v))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to adjust every estimation of y (yhat) so as to minimize the loss function. For that we would deduct a gradient of the loss function from it and continue doing these iterations until we reach the local minimum. \n",
    "$$L_{t+1} =L_t - \\eta\\nabla L_t(W,M,b,v)$$\n",
    "\n",
    "You can think of of gradient as a list of directionsfor improvement (of course, imagining moving in 10000 directions is hard):\n",
    "$$ \\nabla L(W,M,b,v)=\\begin{bmatrix}  \\frac{dL}{dW}\\\\\\frac{dL}{dM}\\\\ \\frac{dL}{db}\\\\ \\frac{dL}{dv}\\end{bmatrix}$$\n",
    "Normally it would be a result of averaging over all observations that went through with forward pass, but again- we have just one this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivation ##\n",
    "\n",
    "refer to the video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Updating weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def loss_derivative(output, y): #check the derivation if interested https://sefiks.com/2017/12/17/a-gentle-introduction-to-cross-entropy-loss-function/\n",
    "    return output - y\n",
    "\n",
    "def ReLU_derivative(x):\n",
    "    return (x>0)*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00635426],\n",
       "       [ 0.01998603],\n",
       "       [ 0.01393413],\n",
       "       [ 0.00850893],\n",
       "       [-0.12060309],\n",
       "       [ 0.07181974]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_error=loss_derivative(oL_outputs, targets)\n",
    "#output_error = (oL_outputs - targets) / oL_outputs.shape[0]\n",
    "output_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden_error=ReLU_derivative(np.dot(weightsHiddenToOutput.T, output_error))\n",
    "hidden_error=np.dot(weightsHiddenToOutput.T, output_error)\n",
    "\n",
    "hidden_error[hL_outputs <= 0] = 0 # instead of relu derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 50)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_HiddenToOutput = np.dot(output_error, np.transpose(hL_outputs))\n",
    "gradient_HiddenToOutput.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 35)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_InputToHidden = np.dot(hidden_error,np.transpose(inputs))\n",
    "gradient_InputToHidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate= 0.01\n",
    "\n",
    "weightsHiddenToOutput -= learningRate *gradient_HiddenToOutput\n",
    "weightsInputToHidden -= learningRate * gradient_InputToHidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent and backpropagation##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from derivatives, avereging over the whole training dataset might be extremely costly. That is why the **stochastic** gradient descent was introduced. It basically means that instead of using the full training set, the algorithm will only use a certain  random **batch** (size of this batch is a hyperparameter like the number of neurons). This introduces a certain \"slopinness\" to the process but allows to run the **backpropagation** much faster and after many iterations we expect to converge to the sample parameters anyway. Anpther important nption is an **epoch** - it means the amount of time the full dataset will be ran through the NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Backpropagation is an algorithm for computing the gradient in multidimensional space.\n",
    "\n",
    "<img src=\"nn_color.png\" alt=\"Backpropagation\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate= 0.01\n",
    "epochs = 10 # here is how many times we want to go through data\n",
    "iteration = 0\n",
    "\n",
    "\n",
    "while iteration < epochs:\n",
    "    \n",
    "    # Put all the steps done before in a loop\n",
    "    # Mind that we are not reinitiating the weights!\n",
    "    for i in range(X.shape[0]):  # we are not using the batches here, we put in the whole dataset\n",
    "   \n",
    "        inputs = np.array(X[i]).reshape( (35,1) )\n",
    "        targets= y[i]\n",
    "        targets = np.array(y[i]).reshape( (6,1) )\n",
    "        \n",
    "\n",
    "        hL_inputs = np.dot(weightsInputToHidden, inputs) + biasInputToHidden\n",
    "        hL_outputs = ReLU(hL_inputs)\n",
    "        oL_inputs = np.dot(weightsHiddenToOutput, hL_outputs) + biasHiddenToOutput \n",
    "        oL_outputs = softmax(oL_inputs)\n",
    "\n",
    "        #L=-sum(targets*np.log(np.round(oL_outputs, 3)))\n",
    "        #print(L)\n",
    "        output_error=loss_derivative(oL_outputs, targets)\n",
    "        hidden_error=np.dot(weightsHiddenToOutput.T, output_error)\n",
    "        hidden_error[hL_outputs <= 0] = 0\n",
    "\n",
    "        gradient_HiddenToOutput = np.dot(output_error, np.transpose(hL_outputs))\n",
    "        gradient_InputToHidden = np.dot(hidden_error,np.transpose(inputs))\n",
    "       \n",
    "        weightsHiddenToOutput -= learningRate *gradient_HiddenToOutput\n",
    "        weightsInputToHidden -= learningRate *gradient_InputToHidden\n",
    "       \n",
    "        \n",
    "\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# scorecard of the network\n",
    "confusion_matrix = np.zeros((6,6), dtype=\"int\" )\n",
    "\n",
    "# go through all the observations in the data set\n",
    "for i in range(len(y)):\n",
    "    inputs = np.array(X[i]).reshape( (35,1) )\n",
    "\n",
    "    hL_inputs = np.dot(weightsInputToHidden, inputs) + biasInputToHidden\n",
    "    hL_outputs = ReLU(hL_inputs)\n",
    "    oL_inputs = np.dot(weightsHiddenToOutput, hL_outputs) + biasHiddenToOutput\n",
    "    oL_outputs = softmax(oL_inputs)\n",
    "\n",
    "    label = np.argmax(oL_outputs)\n",
    "    confusion_matrix[label, y[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1330, 1330,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0],\n",
       "       [   9,    9,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0],\n",
       "       [5855, 5855,    0,    0,    0,    0],\n",
       "       [   3,    3,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate is a **hyper-parameter** that controls how much we are adjusting the weights of our network with respect the loss gradient. \n",
    "Lower LR takes more time but allows better allocation of local minimum, higher LR allows faster calculations but drastic jumps do not always yield good results. \n",
    "        $$ newWeights=OldWeights - learningRate *gradientOfOldWeights$$ \n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/nn3/learningrates.jpeg\" alt=\"Drcng\" style=\"width: 400px;\"/>Img Credit: cs231n\n",
    "\n",
    "One can improve the results of computations significantly if learning rate is set well. However, learning rate might not remain the same throughout the training. The concpet of cyclical learning rate was introduced by Leslie N.Smith in 2015, it conveys a certain schedule when the LR starts with small values and increases (either linearly or exponentially) at each iteration. Learning rate decay would provide an alternative, it would bare the same problem though - when to decay the LR (step decay, exponential decay, others). In practice, step decay is preferred by many practitioners as hyperparameters it involves (the fraction of decay and the step timings in units of epochs) are more interpretable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning_rate = 0.1\n",
    "decay_rate = learning_rate / epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will learn more about hte applications during the next tutorial. Meanwhile, there is another hyperparameter that is often overseen but may yield very good convergence results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Momentum\n",
    "\n",
    "$$\\Delta  W_{i} = -learningRate  \\frac{\\partial L}{\\partial W} + \\mu  \\Delta W_{i-1}$$\n",
    "\n",
    "\n",
    "Second part that contains $\\mu$ is a momentum term here (or coefficient), that defines the effect of the accumulated past gradient (we are aking an exponentially weighted moving average of accumulated gradient). You can think of it as a certain velocity control mechanism. When we reach flatter areas, it will increase the speed of convergence, while dampening oscillations when reaching high curvatures. If learning rate measures how much the current situation affects the next step, while momentum measures how much past steps affect the next step. \n",
    "\n",
    "Conventional values to set for momentum is 0.5 increasing to 0.9, in case of cross validation can be set to values such as [0.5, 0.9, 0.95, 0.99]\n",
    "\n",
    "**Nesterov Momentum** is a slightly different version of the momentum update that has recently been gaining popularity. It is set as a metaparameter in basic Keras application that we will see in the next tutorial. In simplified terms, Nesterov momentum gives gradient a better 'nudge' as it containes a 'lookahead' information. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (adams)",
   "language": "python",
   "name": "pycharm-feb95198"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
